{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,LSTM, Dense, Flatten, Conv1D, Lambda, Reshape, RepeatVector\n",
    "from keras.layers.merge import concatenate, multiply,add\n",
    "from keras import regularizers\n",
    "from keras.initializers import glorot_uniform\n",
    "from tqdm import tqdm\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------change according to local directory----------------------\n",
    "\n",
    "data_dir='../data/'\n",
    "expert_path='../expert_preds/'\n",
    "model_path='../KRNN_models/'\n",
    "checkpoint_dir ='..'\n",
    "\n",
    "\n",
    "dataset='ECG'  #------can be chosen from ['illness','inpatients','ECG']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(ts, label, expert_ts): \n",
    "    \n",
    "    min_in=np.min(ts,axis=1).reshape(ts.shape[0],1)\n",
    "    max_in=np.max(ts,axis=1).reshape(ts.shape[0],1)\n",
    "    denom=max_in-min_in\n",
    "    a = np.where(denom == 0)[0]\n",
    "    denom[a] = max_in[a] \n",
    "    a = np.where(denom == 0)[0]\n",
    "    if a.size>0:\n",
    "        denom[a]=1\n",
    "    ts_norm = (ts-min_in)/denom\n",
    "    expert_ts_norm=(expert_ts-min_in)/denom\n",
    "    input_x = np.append(ts_norm,expert_ts_norm,axis=1)\n",
    "#     input_x=ts_norm\n",
    "    input_y = (label-min_in)/denom\n",
    "    return input_x.reshape(-1,window_size+horizon,1),input_y,expert_ts_norm,min_in,denom\n",
    "    \n",
    "    \n",
    "def prepareData_2(ts, label, expert_ts): \n",
    "    \n",
    "    min_in=np.min(ts,axis=1).reshape(ts.shape[0],1)\n",
    "    max_in=np.max(ts,axis=1).reshape(ts.shape[0],1)\n",
    "    denom=max_in-min_in\n",
    "    a = np.where(denom == 0)[0]\n",
    "    denom[a] = max_in[a] \n",
    "    a = np.where(denom == 0)[0]\n",
    "    if a.size>0:\n",
    "        denom[a]=1\n",
    "    ts_norm = (ts-min_in)/denom\n",
    "    ts_norm = ts_norm.reshape(-1,window_size,1)\n",
    "    expert_ts_norm=(expert_ts-min_in)/denom\n",
    "    \n",
    "    expert_ts_norm1=np.repeat(expert_ts_norm,window_size)\n",
    "    expert_ts_norm1= expert_ts_norm1.reshape(-1,window_size,1)\n",
    "    \n",
    "    input_x = np.append(ts_norm,expert_ts_norm1,axis=2)\n",
    "\n",
    "    input_y = (label-min_in)/denom\n",
    "    return input_x.reshape(-1,window_size,2),input_y,expert_ts_norm,min_in,denom\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def metrics(pred,gt):\n",
    "    l = pred.shape[1]\n",
    "#     print(l)\n",
    "    err_mse = np.zeros((l))\n",
    "    err_mae = np.zeros((l))\n",
    "\n",
    "    for i in range(l):\n",
    "        err_mse[i] = mse(pred[:,i],gt[:,i])\n",
    "        err_mae[i] = mae(pred[:,i],gt[:,i])\n",
    "        \n",
    "    return np.mean(np.sqrt(err_mse)),np.mean(err_mae)\n",
    "def make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]\n",
    "    y = np.zeros([length-window_size+1-horizon,horizon])\n",
    "    output=np.zeros([length-window_size+1-horizon,window_size])\n",
    "    for i in range(length-window_size-horizon+1):\n",
    "        output[i:i+1,:]=data[i:i+window_size]\n",
    "        y[i,:]= data[i+window_size:i+window_size+horizon]\n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    output= np.zeros([length+1-horizon,horizon])\n",
    "    for i in range(length-horizon+1):\n",
    "        output[i:i+1,:]=data[i:i+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)\n",
    "\n",
    "def nonov_make_input(data,window_size,horizon=1):\n",
    "    length=data.shape[0]-window_size\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "\n",
    "    data = np.append(data,np.zeros([horizon-extra]))\n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "        \n",
    "    output=np.zeros([i_val,window_size])\n",
    "    y=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[i*horizon:(i*horizon)+window_size]\n",
    "        y[i,:]= data[(i*horizon)+window_size:(i*horizon)+window_size+horizon]\n",
    "        \n",
    "    return output.reshape(output.shape[0],window_size), y\n",
    "\n",
    "def nonov_make_k_input(data,horizon):\n",
    "    length = data.shape[0]\n",
    "    loop=length//horizon\n",
    "    extra = length%horizon\n",
    "    data_app = np.repeat(data[-1],(horizon-extra))\n",
    "    data = np.append(data,data_app)    \n",
    "\n",
    "    if extra ==0:\n",
    "        i_val = loop\n",
    "    else:\n",
    "        i_val=loop+1\n",
    "    output=np.zeros([i_val,horizon])\n",
    "    for i in range(i_val):\n",
    "        output[i:i+1,:]=data[(i*horizon):(i*horizon)+horizon]\n",
    "    return output.reshape(output.shape[0],horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:03<00:00, 35.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if dataset=='illness':\n",
    "    window_size = 60\n",
    "    horizon = 24\n",
    "    beta=0.001\n",
    "    data=np.asarray(pd.read_csv(data_dir+'national_illness.csv',usecols=[7]))\n",
    "    test_length=193\n",
    "    val_length=77\n",
    "    train_length=966-test_length-val_length\n",
    "    \n",
    "    train=data[:train_length]\n",
    "    m=np.mean(train)\n",
    "    s=np.std(train)\n",
    "    data=(data-m)/s\n",
    "    train=data[:train_length]    \n",
    "    val=data[(train_length-window_size):train_length+val_length]\n",
    "\n",
    "\n",
    "\n",
    "    train_x,train_y = make_input(train[:,0],window_size,horizon)\n",
    "    p_series_train=np.asarray(pd.read_csv(expert_path+dataset+'/train_h_'+str(horizon)+'.csv',index_col=0))\n",
    "    p_series_train= (p_series_train-m)/s\n",
    "    \n",
    "\n",
    "    val_x,val_y = make_input(val[:,0],window_size,horizon)\n",
    "    p_series_val=np.asarray(pd.read_csv(expert_path+dataset+'/val_h_'+str(horizon)+'.csv',index_col=0))\n",
    "    p_series_val= (p_series_val-m)/s\n",
    "   \n",
    "\n",
    "    train_in,train_lbl,train_p,_,_=prepareData(train_x,train_y,p_series_train)\n",
    "    val_in,val_lbl,val_p,_,_=prepareData(val_x,val_y,p_series_val)\n",
    "    \n",
    "    \n",
    "elif dataset =='inpatients':\n",
    "    window_size = 75\n",
    "    horizon = 1\n",
    "    beta=0.01\n",
    "    #----if monthly--------------\n",
    "    # test_length=4\n",
    "    #------if daily---------------\n",
    "    test_length=28\n",
    "    data=np.asarray(pd.read_csv(data_dir+dataset+'/inpatients_daily.csv',header=None))\n",
    "    #------------------------------if monthly-------------------\n",
    "#     data=np.asarray(pd.read_csv(data_dir+dataset+'/inpatients_monthly.csv',header=None))\n",
    "    \n",
    "    train_df = data[0:-test_length]\n",
    "    test_df = data[(-test_length-window_size):]    \n",
    "    train_expert = np.asarray(pd.read_csv(expert_path+dataset+'/d_train.csv',usecols=[1])) \n",
    "    test_expert = np.asarray(pd.read_csv(expert_path+dataset+'/d_test.csv',usecols=[1]))\n",
    "    \n",
    "    #-----------if monthly-----------------\n",
    "#     train_expert = np.asarray(pd.read_csv(expert_path+dataset+'/m_train.csv'musecols=[1])) \n",
    "#     test_expert = np.asarray(pd.read_csv(expert_path+dataset+'/m_test.csv',usecols=[1]))    \n",
    "    \n",
    "    train_sequence=make_input(train_df[:,0],window_size)\n",
    "    test_sequence=make_input(test_df[:,0],window_size)\n",
    "    train_in, train_lbl, train_p, min_in,denom = prepareData_2(train_sequence[0],train_sequence[1], train_expert)\n",
    "    test_in, test_lbl, test_p, min_in_test,denom_test = prepareData_2(test_sequence[0], test_sequence[1], test_expert)\n",
    "    \n",
    "elif dataset=='ECG':\n",
    "    window_size = 12\n",
    "    horizon = 3\n",
    "    test_length= 498\n",
    "    train_x=np.zeros((1,window_size+horizon,1))\n",
    "    train_y=np.zeros((1,horizon))\n",
    "    test_x=train_x\n",
    "    test_y=train_y\n",
    "    p_train=train_y\n",
    "    output=np.zeros([test_length,140])\n",
    "    p_test=test_y\n",
    "    data=np.asarray(pd.read_csv(data_dir+dataset+'/ECG_data.csv',header=None))\n",
    "    with tqdm(total=140) as pbar:\n",
    "        for i in range(data.shape[1]):\n",
    "            train_length=4500\n",
    "            \n",
    "            ts=data[:train_length,i]\n",
    "            ts_x,ts_y = make_input(ts,window_size,horizon)\n",
    "            p_series_train=np.asarray(pd.read_csv(expert_path+dataset+'/ECG_train/ECG_train_'+str(i+1)+'.csv',index_col=0))\n",
    "            ts_train,ts_label,ts_p_train,_,_=prepareData(ts_x,ts_y,p_series_train)\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            train_x=np.append(train_x,ts_train,axis=0)\n",
    "            train_y=np.append(train_y,ts_label,axis=0)\n",
    "            p_train=np.append(p_train,ts_p_train,axis=0)\n",
    "    train_lbl=train_y[1:,:]\n",
    "    train_p=p_train[1:,:]\n",
    "    train_in=train_x[1:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4998, 140)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------for testing-------------------------------------------\n",
    "\n",
    "if dataset=='illness':\n",
    "\n",
    "    model=load_model(model_path+dataset+'/krnn_'+str(horizon)+'_1.h5')\n",
    "    ts_test=data[-(test_length+window_size):]\n",
    "\n",
    "    ts_test_x,ts_test_y = nonov_make_input(ts_test[:,0],window_size,horizon)\n",
    "    p_series_test=(np.asarray(pd.read_csv(expert_path+dataset+'/test_h_'+str(horizon)+'.csv',index_col=0))-m)/s\n",
    "\n",
    "\n",
    "    ts_test,ts_label,ts_p_test,min_in,denom=prepareData(ts_test_x,ts_test_y,p_series_test)\n",
    "    preds= model.predict([ts_test,ts_p_test])\n",
    "\n",
    "    prediction=preds*denom+min_in\n",
    "    prediction=prediction.flatten()[:test_length]\n",
    "    \n",
    "elif dataset=='inpatients':\n",
    "    model=load_model(model_path+dataset+'/krnn_daily.h5')\n",
    "    preds = model.predict(([test_X, expert_test]), batch_size=1)\n",
    "    prediction = (preds*denom_test+min_in_test)\n",
    "\n",
    "elif dataset=='ECG':\n",
    "    model=load_model(model_path+dataset+'/krnn.h5')\n",
    "    output=np.zeros([test_length,140])\n",
    "    for i in range(data.shape[1]):\n",
    "        train_length=4500\n",
    "\n",
    "        ts=data[(train_length-window_size):,i]\n",
    "        ts_x,ts_y = nonov_make_input(ts,window_size,horizon)\n",
    "        p_series_test=np.asarray(pd.read_csv(expert_path+dataset+'/ECG_test/ECG_test_'+str(i+1)+'.csv',index_col=0))\n",
    "        ts_test,ts_label,ts_p_test,min_in,denom=prepareData(ts_x[:,:],ts_y[:,:],p_series_test)\n",
    "\n",
    "\n",
    "        preds= model.predict([ts_test,ts_p_test])\n",
    "\n",
    "        prediction=preds*denom+min_in\n",
    "        prediction=prediction.flatten()[:498]\n",
    "\n",
    "        output[:,i]=np.transpose(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.44993350159089496\n",
      "MAE = 0.32220367374190334\n"
     ]
    }
   ],
   "source": [
    "if dataset=='ECG':\n",
    "    temp1, temp2= metrics(output,data[-test_length:,:])\n",
    "    \n",
    "    print('RMSE = '+str(np.mean(temp1)))\n",
    "    print('MAE = '+str(temp2))\n",
    "else:\n",
    "    Metrics=[np.sqrt(mse(prediction,data[-test_length:,0])),mae(prediction,data[-test_length:,0])]\n",
    "\n",
    "    print('RMSE = '+str(Metrics[0]))\n",
    "    print('MAE = '+str(Metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 84, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 84, 512)      1052672     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 84, 64)       147712      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           12416       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 24)           792         lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 24)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 24)           0           dense_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,213,592\n",
      "Trainable params: 1,213,592\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------For re-training -----------------------------\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "\n",
    "if dataset=='illness':\n",
    "    inputs_train= Input(batch_shape=(None, window_size+horizon, 1))\n",
    "    inputs_expert = Input(batch_shape=(None, horizon))\n",
    "\n",
    "\n",
    "    layer1 = LSTM(512, activation='relu',dropout=0.1, return_sequences=True)(inputs_train)\n",
    "    layer2 = LSTM(64, activation='relu',dropout=0.1,return_sequences=True)(layer1)\n",
    "    layer3 = LSTM(32, activation='relu')(layer2)\n",
    "    layer4 = Dense(horizon,activity_regularizer=regularizers.l2(beta))(layer3)\n",
    "    residual = add([layer4, inputs_expert])\n",
    "\n",
    "    model=Model(inputs=[inputs_train, inputs_expert], outputs=residual)\n",
    "    \n",
    "    \n",
    "elif dataset=='inpatients'\n",
    "    inputs_train= Input(batch_shape=(None,window_size,2))   \n",
    "    inputs_expert = Input(batch_shape=(None, 1))\n",
    "\n",
    "    layer1 = Conv1D(16,3, activation='relu')(inputs_train)\n",
    "    layer2 = Conv1D(8,3, activation='relu')(layer1)  \n",
    "    layer2=Flatten()(layer2)\n",
    "    layer2=Dense(1,activity_regularizer=regularizers.l2(beta))(layer2)    \n",
    "    residual = add([layer2, inputs_expert])\n",
    "    \n",
    "    model=Model(inputs=[inputs_train, inputs_expert], outputs=residual)\n",
    "    \n",
    "    \n",
    "elif dataset=='ECG':\n",
    "    inputs_train= Input(batch_shape=(None, window_size+horizon, 1))    \n",
    "    inputs_expert = Input(batch_shape=(None, horizon))\n",
    "\n",
    "    branch_0 = Conv1D(128,3, strides=1, padding='same',activation='relu',kernel_initializer=glorot_uniform(1))(inputs_train)\n",
    "    branch_0 = Conv1D(128,3, strides=1, padding='same',activation='relu',kernel_initializer=glorot_uniform(1))(branch_0)\n",
    "    layer3=Flatten()(branch_0)\n",
    "    layer4 = Dense(horizon,activity_regularizer=regularizers.l2(0.0001))(layer3)\n",
    "    residual = add([layer4, inputs_expert])\n",
    "\n",
    "\n",
    "    model=Model(inputs=[inputs_train, inputs_expert], outputs=residual)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 601 samples, validate on 42 samples\n",
      "Epoch 1/100\n",
      "601/601 [==============================] - 10s 17ms/step - loss: 0.2300 - val_loss: 0.2982\n",
      "Epoch 2/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2291 - val_loss: 0.2961\n",
      "Epoch 3/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2277 - val_loss: 0.2927\n",
      "Epoch 4/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2260 - val_loss: 0.2883\n",
      "Epoch 5/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2244 - val_loss: 0.2855\n",
      "Epoch 6/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2204 - val_loss: 0.2757\n",
      "Epoch 7/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2220 - val_loss: 0.2812\n",
      "Epoch 8/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2169 - val_loss: 0.2684\n",
      "Epoch 9/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.3143 - val_loss: 0.2577\n",
      "Epoch 10/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2115 - val_loss: 0.2633\n",
      "Epoch 11/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2105 - val_loss: 0.2603\n",
      "Epoch 12/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2083 - val_loss: 0.2567\n",
      "Epoch 13/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2060 - val_loss: 0.2517\n",
      "Epoch 14/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.2011 - val_loss: 0.2425\n",
      "Epoch 15/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1950 - val_loss: 0.2240\n",
      "Epoch 16/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1947 - val_loss: 0.2331\n",
      "Epoch 17/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1907 - val_loss: 0.2151\n",
      "Epoch 18/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1806 - val_loss: 0.2323\n",
      "Epoch 19/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1906 - val_loss: 0.2323\n",
      "Epoch 20/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1876 - val_loss: 0.2222\n",
      "Epoch 21/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1837 - val_loss: 0.2068\n",
      "Epoch 22/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1771 - val_loss: 0.1933\n",
      "Epoch 23/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1702 - val_loss: 0.1791\n",
      "Epoch 24/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1669 - val_loss: 0.1668\n",
      "Epoch 25/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1612 - val_loss: 0.1786\n",
      "Epoch 26/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1639 - val_loss: 0.1649\n",
      "Epoch 27/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1603 - val_loss: 0.2019\n",
      "Epoch 28/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1821 - val_loss: 0.2172\n",
      "Epoch 29/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1805 - val_loss: 0.2095\n",
      "Epoch 30/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1775 - val_loss: 0.1993\n",
      "Epoch 31/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1712 - val_loss: 0.1891\n",
      "Epoch 32/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1655 - val_loss: 0.1784\n",
      "Epoch 33/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1637 - val_loss: 0.1668\n",
      "Epoch 34/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1558 - val_loss: 0.1483\n",
      "Epoch 35/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1476 - val_loss: 0.1298\n",
      "Epoch 36/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1417 - val_loss: 0.1246\n",
      "Epoch 37/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1358 - val_loss: 0.1243\n",
      "Epoch 38/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1354 - val_loss: 0.1383\n",
      "Epoch 39/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1378 - val_loss: 0.1105\n",
      "Epoch 40/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1298 - val_loss: 0.1199\n",
      "Epoch 41/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1246 - val_loss: 0.1316\n",
      "Epoch 42/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1305 - val_loss: 0.1042\n",
      "Epoch 43/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1279 - val_loss: 0.1311\n",
      "Epoch 44/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1300 - val_loss: 0.1345\n",
      "Epoch 45/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1365 - val_loss: 0.1241\n",
      "Epoch 46/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1223 - val_loss: 0.1284\n",
      "Epoch 47/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1309 - val_loss: 0.1136\n",
      "Epoch 48/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1212 - val_loss: 0.1098\n",
      "Epoch 49/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1171 - val_loss: 0.0975\n",
      "Epoch 50/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1188 - val_loss: 0.1015\n",
      "Epoch 51/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1180 - val_loss: 0.1014\n",
      "Epoch 52/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1105 - val_loss: 0.0996\n",
      "Epoch 53/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1110 - val_loss: 0.1107\n",
      "Epoch 54/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1174 - val_loss: 0.1035\n",
      "Epoch 55/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1117 - val_loss: 0.1051\n",
      "Epoch 56/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1107 - val_loss: 0.1037\n",
      "Epoch 57/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1135 - val_loss: 0.0998\n",
      "Epoch 58/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1076 - val_loss: 0.1064\n",
      "Epoch 59/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1065 - val_loss: 0.1013\n",
      "Epoch 60/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1075 - val_loss: 0.0990\n",
      "Epoch 61/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1043 - val_loss: 0.0938\n",
      "Epoch 62/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1071 - val_loss: 0.0898\n",
      "Epoch 63/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1071 - val_loss: 0.0955\n",
      "Epoch 64/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0986 - val_loss: 0.0891\n",
      "Epoch 65/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1016 - val_loss: 0.0889\n",
      "Epoch 66/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0986 - val_loss: 0.0877\n",
      "Epoch 67/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0979 - val_loss: 0.0862\n",
      "Epoch 68/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.9268 - val_loss: 0.1119\n",
      "Epoch 69/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1278 - val_loss: 0.1062\n",
      "Epoch 70/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1237 - val_loss: 0.1601\n",
      "Epoch 71/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1459 - val_loss: 0.1338\n",
      "Epoch 72/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1158 - val_loss: 0.1207\n",
      "Epoch 73/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1309 - val_loss: 0.1258\n",
      "Epoch 74/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1194 - val_loss: 0.0880\n",
      "Epoch 75/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1072 - val_loss: 0.0899\n",
      "Epoch 76/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1121 - val_loss: 0.0976\n",
      "Epoch 77/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1150 - val_loss: 0.0967\n",
      "Epoch 78/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1160 - val_loss: 0.0929\n",
      "Epoch 79/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1039 - val_loss: 0.0949\n",
      "Epoch 80/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1053 - val_loss: 0.0950\n",
      "Epoch 81/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1066 - val_loss: 0.0913\n",
      "Epoch 82/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1035 - val_loss: 0.0895\n",
      "Epoch 83/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1037 - val_loss: 0.0915\n",
      "Epoch 84/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1013 - val_loss: 0.0988\n",
      "Epoch 85/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1007 - val_loss: 0.0981\n",
      "Epoch 86/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1029 - val_loss: 0.0851\n",
      "Epoch 87/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1038 - val_loss: 0.0889\n",
      "Epoch 88/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0957 - val_loss: 0.0928\n",
      "Epoch 89/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0981 - val_loss: 0.0937\n",
      "Epoch 90/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1025 - val_loss: 0.0853\n",
      "Epoch 91/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0992 - val_loss: 0.0870\n",
      "Epoch 92/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0993 - val_loss: 0.0935\n",
      "Epoch 93/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0988 - val_loss: 0.0905\n",
      "Epoch 94/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1019 - val_loss: 0.0902\n",
      "Epoch 95/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.0944 - val_loss: 0.0837\n",
      "Epoch 96/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1403 - val_loss: 0.2158\n",
      "Epoch 97/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1759 - val_loss: 0.2113\n",
      "Epoch 98/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1686 - val_loss: 0.1996\n",
      "Epoch 99/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1612 - val_loss: 0.1866\n",
      "Epoch 100/100\n",
      "601/601 [==============================] - 7s 12ms/step - loss: 0.1534 - val_loss: 0.1730\n"
     ]
    }
   ],
   "source": [
    "callback = ModelCheckpoint(filepath=checkpoint_dir+'krnn_'+str(horizon)+'_1.h5',monitor='val_loss',save_best_only=True)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.0001))\n",
    "if dataset=='illness':\n",
    "    hist=model.fit({'input_1':train_in,'input_2':train_p},train_lbl,validation_data=[[val_in,val_p],val_lbl],callbacks=[callback],batch_size=32,shuffle=False, epochs=100,verbose=1)\n",
    "else:\n",
    "    hist=model.fit({'input_1':train_in,'input_2':train_p},train_lbl,validation_split=0.1,callbacks=[callback],batch_size=32,shuffle=False, epochs=100,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
